# Statistical Testing {#sec-statistical-testing}

## Statistical Tests

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(janitor)
library(survey)
library(srvyr)
library(gtsummary)
```

```{r include=FALSE}
load("input/api.Rdata")
```

Start with univariate analyses. Plot distributions for the continuous variables. Get in the habit of weighting outcomes even though it has no effect in SRS.

::: panel-tabset

### Histogram

```{r}
#| label: fig-hist
#| fig.cap: Histogram of Academic Performance Index in 2020.
apisrs_des |>
  ggplot(aes(x = api00)) + geom_histogram(aes(weight = pw))
```

### Boxplot 

```{r}
#| label: fig-box
#| fig.cap: Boxplot of Academic Performance Index in 2020 by whether met school-wide target.
apisrs_des |>
  ggplot(aes(x = sch.wide, y = api00)) + 
  geom_boxplot(aes(weight = pw))

```

:::

The `srvyr::summarize()`function automatically creates standard errors and confidence intervals using the weights from the design object. The formulas are simple with SRS, so you could calculate them this yourself. *gtsummary* has limited support for tables.

::: panel-tabset

### srvyr

```{r}
apisrs_des |>
  summarize(
    .by = sch.wide, 
    api00 = survey_mean(api00, vartype = c("se", "ci", "cv", "var"))
  ) |>
  knitr::kable()
```

### manual

```{r}
apisrs |>
  summarize(
    .by = sch.wide,
    M = mean(api00), 
    s = sd(api00), 
    n = n(), 
    se = s*sqrt(1 - n / 6194)/sqrt(n), 
    t = qt(.975, n-1, FALSE), 
    ci_025 = M - se * t, 
    ci_975 = M + se * t,
    cv = se / M
) |>
  knitr::kable()
```

### gtsummary

```{r}
apisrs_des |> 
  gtsummary::tbl_svysummary(
    by = sch.wide,
    statistic = list(all_continuous() ~ "{mean} ({p25}, {p75}), {mean.std.error}"),
    include = "api00"
  ) |>
  gtsummary::add_ci()
```

:::


#### Example {-}

Data set `apisrs` is a simple random sample of the Academic Performance Index (API) of *n* = 200 of the *N* = 6,194 schools in California. 

All **survey** objects require that you specify the columns identifying the clusters from largest to smallest level. In simple random designs like this, there are no clusters, and you specify just the constant `id = ~1`. The `fpc` parameter specifies the column with the finite population correction. In a simple random sample, it equals *N*. The `fpc` functions to both adjust the variance estimate, and to set the observation weights.

```{r}
srs_design <- svydesign(id = ~1,  fpc = ~fpc, data = apisrs)
```

$\hat{T}_X$, $\mathrm{var} [\hat{T}_X]$, $\hat{\mu}_X$, and $\hat{\mathrm{var}}[\hat{\mu}_X]$ are

```{r collapse=TRUE}
svytotal(~enroll, srs_design)
svymean(~enroll, srs_design)
```

When the sample is much smaller than the population, the finite population correction makes little difference. You can omit the `fpc` parameter, but then you must supply the samplying weight instead. In this case, the sampling weight is 200/6194, and is in variable `pw`. The total and mean are unchanged, but the variance increases a little without the correction.

```{r collapse=TRUE}
srs_design2 <- svydesign(id = ~1, weights = ~pw, data = apisrs)
svytotal(~enroll, srs_design2)
svymean(~enroll, srs_design2)
```


